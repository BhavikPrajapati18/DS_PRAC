{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/ZwfNPzU9aNoFL8t8pOah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhavikPrajapati18/DS_PRAC/blob/main/Ques7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling – Standardization & Normalization"
      ],
      "metadata": {
        "id": "OkzF9qMdJUBJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kNOcmgKKvs30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da0e187-7f65-417b-be91-88f8c3c92d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Make      Model  Mileage  SellPrice  Mileage_std  SellPrice_std  \\\n",
            "0       Honda     Accord    63512       4000    -0.727329       0.388669   \n",
            "1       Honda     Accord    95135       2500     0.477794      -1.391249   \n",
            "2      Toyota      Camry    75006       4500    -0.289303       0.981976   \n",
            "3      Nissan     Altima    69847       3826    -0.485908       0.182199   \n",
            "4      Toyota    Corolla    87278       2224     0.178371      -1.718754   \n",
            "5       Honda      Civic   138789       2723     2.141407      -1.126634   \n",
            "6        Ford      F-150    89073       3273     0.246777      -0.473998   \n",
            "7   Chevrolet  Silverado   109231       4959     1.014979       1.526631   \n",
            "8   Chevrolet     Impala    87675       3791     0.193500       0.140667   \n",
            "9       Dodge    Charger    34853       4349    -1.819496       0.802797   \n",
            "10      Dodge    Charger    58173       4252    -0.930793       0.687696   \n",
            "\n",
            "    Mileage_norm  SellPrice_norm  \n",
            "0       0.275737        0.649360  \n",
            "1       0.579992        0.100914  \n",
            "2       0.386324        0.832176  \n",
            "3       0.336688        0.585740  \n",
            "4       0.504397        0.000000  \n",
            "5       1.000000        0.182450  \n",
            "6       0.521667        0.383547  \n",
            "7       0.715613        1.000000  \n",
            "8       0.508217        0.572943  \n",
            "9       0.000000        0.776965  \n",
            "10      0.224369        0.741499  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Step 1: Create the data\n",
        "data = {\n",
        "    'Make': ['Honda', 'Honda', 'Toyota', 'Nissan', 'Toyota', 'Honda', 'Ford', 'Chevrolet', 'Chevrolet', 'Dodge', 'Dodge'],\n",
        "    'Model': ['Accord', 'Accord', 'Camry', 'Altima', 'Corolla', 'Civic', 'F-150', 'Silverado', 'Impala', 'Charger', 'Charger'],\n",
        "    'Color': ['Red', 'Blue', 'Black', 'Green', 'Black', 'White', 'Black', 'Green', 'Silver', 'Silver', 'Silver'],\n",
        "    'Mileage': [63512, 95135, 75006, 69847, 87278, 138789, 89073, 109231, 87675, 34853, 58173],\n",
        "    'SellPrice': [4000, 2500, 4500, 3826, 2224, 2723, 3273, 4959, 3791, 4349, 4252]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Standardization\n",
        "scaler_std = StandardScaler()\n",
        "df[['Mileage_std', 'SellPrice_std']] = scaler_std.fit_transform(df[['Mileage', 'SellPrice']])\n",
        "\n",
        "# Step 3: Normalization\n",
        "scaler_norm = MinMaxScaler()\n",
        "df[['Mileage_norm', 'SellPrice_norm']] = scaler_norm.fit_transform(df[['Mileage', 'SellPrice']])\n",
        "\n",
        "# Step 4: Display results\n",
        "print(df[['Make', 'Model', 'Mileage', 'SellPrice', 'Mileage_std', 'SellPrice_std', 'Mileage_norm', 'SellPrice_norm']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Linear Regression – Pima Diabetes Dataset"
      ],
      "metadata": {
        "id": "Uf6nJsDHJczS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Load dataset from GitHub (Pima Indian Diabetes)\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "\n",
        "# Assign column names\n",
        "cols = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\",\n",
        "        \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "df = pd.read_csv(url, names=cols)\n",
        "\n",
        "# Step 1: Prepare Data\n",
        "X = df.drop(\"Outcome\", axis=1)\n",
        "y = df[\"Outcome\"]\n",
        "\n",
        "# Step 2: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "XfFqVW2zLR-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0408f084-da82-4664-808b-e4f3954cbe1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.7467532467532467\n",
            "\n",
            "Confusion Matrix:\n",
            " [[78 21]\n",
            " [18 37]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.79      0.80        99\n",
            "           1       0.64      0.67      0.65        55\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.73      0.73       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "5mHriNIqv9fz"
      }
    }
  ]
}